{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0vTe0gp9NbwT",
        "rI4WRAoyNi2S",
        "BDzq493bsT24"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Nails"
      ],
      "metadata": {
        "id": "0vTe0gp9NbwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-BRzAhSNbAB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2x0zwW4P54kBPyKWFAsAj1VdmY5_37CvA5hzRApq4UAcyK1vq\")\n"
      ],
      "metadata": {
        "id": "5K4I1PEAbCPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Imports ----\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import io, base64\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import joblib\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch import nn\n",
        "\n",
        "# ---- Init ----\n",
        "app = FastAPI()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ---- Anemia Detection Model ----\n",
        "model = joblib.load(\"/content/drive/My Drive/Grad/API/nails/random_forest_model.pkl\")\n",
        "\n",
        "def extract_features(image: Image.Image):\n",
        "    image = image.resize((128, 128))\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    if image_np.ndim == 2:\n",
        "        image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)\n",
        "    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    hsv = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 256, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist.reshape(1, -1)\n",
        "\n",
        "@app.post(\"/predict-anemia\")\n",
        "async def predict_anemia(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        image = Image.open(io.BytesIO(contents))\n",
        "        features = extract_features(image)\n",
        "        prediction = model.predict(features)[0]\n",
        "        confidence = (\n",
        "            np.max(model.predict_proba(features)) if hasattr(model, \"predict_proba\") else 1.0\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"label\": str(prediction),\n",
        "            \"confidence\": round(float(confidence), 3)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ---- Nail Segmentation Model ----\n",
        "seg_model = models.segmentation.deeplabv3_resnet101(weights=None, aux_loss=True)\n",
        "seg_model.classifier[4] = nn.Conv2d(256, 1, 1)\n",
        "seg_model.aux_classifier[4] = nn.Conv2d(256, 1, 1)\n",
        "seg_model.load_state_dict(torch.load(\"/content/drive/My Drive/Grad/API/nails/segmentation_nails.pth\", map_location=device))\n",
        "seg_model.to(device)\n",
        "seg_model.eval()\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "raw_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "@app.post(\"/segment-nail\")\n",
        "async def segment_nail(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        img_pil = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
        "        img_tensor = img_transform(img_pil).unsqueeze(0).to(device)\n",
        "        raw_tensor = raw_transform(img_pil)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = seg_model(img_tensor)['out']\n",
        "            pred_mask = torch.sigmoid(output)\n",
        "            pred_mask = (pred_mask > 0.5).float().cpu().squeeze(0)\n",
        "\n",
        "        masked_rgb = raw_tensor * pred_mask\n",
        "        masked_np = masked_rgb.permute(1, 2, 0).numpy()\n",
        "        masked_np = np.clip(masked_np * 255, 0, 255).astype(np.uint8)\n",
        "        masked_pil = Image.fromarray(masked_np)\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "        masked_pil.save(buffer, format=\"PNG\")\n",
        "        base64_img = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "        return {\"masked_image_base64\": base64_img}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ---- Run the Server ----\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"🚀 Public URL: {public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "oTqG1w284fPV",
        "outputId": "51f552f1-3f2a-414d-85de-278d105378fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [42966]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Public URL: NgrokTunnel: \"https://90e9-35-185-110-31.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Event loop stopped before Future completed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7be2995df6a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🚀 Public URL: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.0.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# pragma: full coverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Event loop stopped before Future completed."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Palm"
      ],
      "metadata": {
        "id": "rI4WRAoyNi2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1PR5EcX1mgp"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBB-JuIm1pgW"
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpnG2M9k2h8T"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 2x0zwW4P54kBPyKWFAsAj1VdmY5_37CvA5hzRApq4UAcyK1vq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAoFEaAaclNb"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import io, base64\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "anemia_model = joblib.load(\"/content/drive/MyDrive/Grad/API/Palm/RF-balancedPalm.pkl\")\n",
        "segmentation_model = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Grad/API/Palm/palm_segmentation_model.h5\",\n",
        "    compile=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEHGr6vE1S-y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def extract_color_histogram(image: Image.Image):\n",
        "    image = image.resize((128, 128))\n",
        "    img_np = np.array(image)\n",
        "\n",
        "    if img_np.ndim == 2:\n",
        "        img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
        "    hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 256, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist.reshape(1, -1)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"API is running. Try /segment-and-predict\"}\n",
        "\n",
        "@app.post(\"/segment-and-predict\")\n",
        "async def segment_and_predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
        "        image_resized = image.resize((128, 128))\n",
        "        image_np = np.array(image_resized) / 255.0\n",
        "\n",
        "        pred_mask = segmentation_model.predict(np.expand_dims(image_np, axis=0))[0]\n",
        "        mask = (pred_mask.squeeze() > 0.5).astype(np.uint8)\n",
        "\n",
        "        masked_image = np.array(image_resized) * np.expand_dims(mask, axis=-1)\n",
        "        masked_image = masked_image.astype(np.uint8)\n",
        "\n",
        "        masked_pil = Image.fromarray(masked_image)\n",
        "        features = extract_color_histogram(masked_pil)\n",
        "        prediction = anemia_model.predict(features)[0]\n",
        "        confidence = anemia_model.predict_proba(features)[0][prediction]\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "        masked_pil.save(buffer, format=\"PNG\")\n",
        "        base64_img = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "        return {\n",
        "            \"label\": str(prediction),\n",
        "            \"confidence\": round(float(confidence), 3),\n",
        "            \"masked_image_base64\": base64_img\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDzq493bsT24"
      },
      "source": [
        "# Conjunctiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helPLIszsTRe"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi[all]\n",
        "!pip install nest_asyncio pyngrok\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ngrok config add-authtoken 2x0zwW4P54kBPyKWFAsAj1VdmY5_37CvA5hzRApq4UAcyK1vq\n",
        "\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import io, base64\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Load models\n",
        "anemia_model_conjunctiva = joblib.load(\"/content/drive/MyDrive/Grad/API/Conjunctiva/xgboost_tunnig_model.pkl\")\n",
        "segmentation_model_conjunctiva = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Grad/API/Conjunctiva/conjunctiva_unet_best_model.h5\",\n",
        "    compile=False\n",
        ")\n",
        "\n",
        "# Function to extract color histogram features\n",
        "def extract_color_histogram(image: Image.Image):\n",
        "    image = image.resize((128, 128))\n",
        "    img_np = np.array(image)\n",
        "\n",
        "    if img_np.ndim == 2:\n",
        "        img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
        "    hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 256, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist.reshape(1, -1)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Conjunctiva API is running. Try /segment-and-predict\"}\n",
        "\n",
        "@app.post(\"/segment-and-predict\")\n",
        "async def segment_and_predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        # Read the uploaded image\n",
        "        contents = await file.read()\n",
        "        image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
        "        image_resized = image.resize((128, 128))\n",
        "        image_np = np.array(image_resized)\n",
        "\n",
        "        # Convert RGB -> BGR\n",
        "        image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Normalize\n",
        "        image_bgr_norm = image_bgr.astype(np.float32) / 255.0\n",
        "\n",
        "        # Apply segmentation model\n",
        "        pred_mask = segmentation_model_conjunctiva.predict(np.expand_dims(image_bgr_norm, axis=0))[0]\n",
        "\n",
        "        # Remove last dimension if exists\n",
        "        if len(pred_mask.shape) == 3:\n",
        "            pred_mask = pred_mask.squeeze(-1)\n",
        "\n",
        "        # Threshold mask to obtain binary output\n",
        "        mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        # Apply mask to the image (RGB version for display)\n",
        "        masked_image = image_np * np.expand_dims(mask, axis=-1)\n",
        "        masked_image = masked_image.astype(np.uint8)\n",
        "\n",
        "        masked_pil = Image.fromarray(masked_image)\n",
        "        features = extract_color_histogram(masked_pil)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = anemia_model_conjunctiva.predict(features)[0]\n",
        "        confidence = anemia_model_conjunctiva.predict_proba(features)[0][prediction]\n",
        "\n",
        "        # Convert masked image to base64 string\n",
        "        buffer = io.BytesIO()\n",
        "        masked_pil.save(buffer, format=\"PNG\")\n",
        "        base64_img = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "        return {\n",
        "            \"label\": str(prediction),\n",
        "            \"confidence\": round(float(confidence), 3),\n",
        "            \"masked_image_base64\": base64_img\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Apply ngrok for public URL and run the FastAPI server\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Three Model API"
      ],
      "metadata": {
        "id": "VhURI9wkORES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfHeYzRfYtqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480b8f35-6e0a-4bcd-8a53-0cbffeaf2fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn nest-asyncio pyngrok scikit-learn joblib pillow python-multipart\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2x0zwW4P54kBPyKWFAsAj1VdmY5_37CvA5hzRApq4UAcyK1vq\n",
        "\n"
      ],
      "metadata": {
        "id": "oMTNtp13GlLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cec530-5d06-44bf-e3cc-64de094b93d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJcqPnDL0PbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30b6b98-dd96-4f60-8671-903e5dabf3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### new\n"
      ],
      "metadata": {
        "id": "cCZceumDNoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages if needed\n",
        "# !pip install fastapi uvicorn nest-asyncio pyngrok scikit-learn joblib pillow python-multipart tensorflow opencv-python-headless\n",
        "\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import io, base64\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch import nn\n",
        "import traceback\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Device for PyTorch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ----- Load All Models -----\n",
        "\n",
        "# Nails Models\n",
        "nail_rf_model = joblib.load(\"/content/drive/My Drive/Grad/API/nails/random_forest_model.pkl\")\n",
        "nail_seg_model = models.segmentation.deeplabv3_resnet101(weights=None, aux_loss=True)\n",
        "nail_seg_model.classifier[4] = nn.Conv2d(256, 1, 1)\n",
        "nail_seg_model.aux_classifier[4] = nn.Conv2d(256, 1, 1)\n",
        "nail_seg_model.load_state_dict(torch.load(\"/content/drive/My Drive/Grad/API/nails/segmentation_nails.pth\", map_location=device))\n",
        "nail_seg_model.to(device).eval()\n",
        "\n",
        "# Palm Models\n",
        "palm_rf_model = joblib.load(\"/content/drive/MyDrive/Grad/API/Palm/RF-balancedPalm.pkl\")\n",
        "palm_seg_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Grad/API/Palm/palm_segmentation_model.h5\", compile=False)\n",
        "\n",
        "# Conjunctiva Models\n",
        "conj_rf_model = joblib.load(\"/content/drive/MyDrive/Grad/API/Conjunctiva/xgboost_model.pkl\")\n",
        "conj_seg_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Grad/API/Conjunctiva/conjunctiva_unet_best_model.h5\", compile=False)\n",
        "\n",
        "\n",
        "# ----- Utility Functions -----\n",
        "\n",
        "# Histogram extractor (common for all)\n",
        "def extract_color_histogram(image: Image.Image):\n",
        "    image = image.resize((128, 128))\n",
        "    img_np = np.array(image)\n",
        "    if img_np.ndim == 2:\n",
        "        img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
        "    hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8, 8, 8), [0, 256, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist.reshape(1, -1)\n",
        "\n",
        "# Nails segmentation (Safe)\n",
        "def segment_nail(image: Image.Image):\n",
        "    image = image.convert(\"RGB\").resize((224, 224))\n",
        "    img_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "    img_tensor = img_transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = nail_seg_model(img_tensor)['out']\n",
        "        pred_mask = torch.sigmoid(output)\n",
        "        pred_mask = (pred_mask > 0.5).float().cpu().squeeze(0)\n",
        "    raw_tensor = transforms.ToTensor()(image)\n",
        "    masked_rgb = raw_tensor * pred_mask\n",
        "    masked_np = masked_rgb.permute(1, 2, 0).numpy()\n",
        "    masked_np = np.clip(masked_np * 255, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(masked_np)\n",
        "\n",
        "# Palm segmentation (Safe)\n",
        "def segment_palm(image: Image.Image):\n",
        "    image = image.convert(\"RGB\").resize((128, 128))\n",
        "    image_np = np.array(image) / 255.0\n",
        "    pred_mask = palm_seg_model.predict(np.expand_dims(image_np, axis=0))[0]\n",
        "    mask = (pred_mask.squeeze() > 0.5).astype(np.uint8)\n",
        "    masked_image = np.array(image) * np.expand_dims(mask, axis=-1)\n",
        "    return Image.fromarray(masked_image.astype(np.uint8))\n",
        "\n",
        "# Conjunctiva segmentation (Safe)\n",
        "def segment_conjunctiva(image: Image.Image):\n",
        "    image = image.convert(\"RGB\").resize((256, 256))\n",
        "    image_np = np.array(image)\n",
        "    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    image_bgr_norm = image_bgr.astype(np.float32) / 255.0\n",
        "    pred_mask = conj_seg_model.predict(np.expand_dims(image_bgr_norm, axis=0))[0]\n",
        "    if len(pred_mask.shape) == 3:\n",
        "        pred_mask = pred_mask.squeeze(-1)\n",
        "    mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "    masked_image = image_np * np.expand_dims(mask, axis=-1)\n",
        "    return Image.fromarray(masked_image.astype(np.uint8))\n",
        "\n",
        "\n",
        "# ----- Combine Results Logic -----\n",
        "def combine_results(predictions: list):\n",
        "    anemic_count = predictions.count(0)\n",
        "    if anemic_count == 3:\n",
        "        return \"High likelihood Anemic\"\n",
        "    elif anemic_count == 2:\n",
        "        return \"Moderate likelihood Anemic\"\n",
        "    elif anemic_count == 1:\n",
        "        return \"Low likelihood Anemic\"\n",
        "    else:\n",
        "        return \"Healthy\"\n",
        "\n",
        "\n",
        "# ----- API Endpoint -----\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict_all(nail: UploadFile = File(...), palm: UploadFile = File(...), conjunctiva: UploadFile = File(...)):\n",
        "    try:\n",
        "        result = {}\n",
        "\n",
        "        # ---- Nail ----\n",
        "        try:\n",
        "            nail_img = Image.open(io.BytesIO(await nail.read()))\n",
        "            nail_masked = segment_nail(nail_img)\n",
        "            nail_feat = extract_color_histogram(nail_masked)\n",
        "            nail_pred = nail_rf_model.predict(nail_feat)[0]\n",
        "            result['nail_prediction'] = int(nail_pred)\n",
        "        except Exception as e:\n",
        "            traceback.print_exc()\n",
        "            result['nail_prediction'] = None\n",
        "\n",
        "        # ---- Palm ----\n",
        "        try:\n",
        "            palm_img = Image.open(io.BytesIO(await palm.read()))\n",
        "            palm_masked = segment_palm(palm_img)\n",
        "            palm_feat = extract_color_histogram(palm_masked)\n",
        "            palm_pred = palm_rf_model.predict(palm_feat)[0]\n",
        "            result['palm_prediction'] = int(palm_pred)\n",
        "        except Exception as e:\n",
        "            traceback.print_exc()\n",
        "            result['palm_prediction'] = None\n",
        "\n",
        "        # ---- Conjunctiva ----\n",
        "        try:\n",
        "            conj_img = Image.open(io.BytesIO(await conjunctiva.read()))\n",
        "            conj_masked = segment_conjunctiva(conj_img)\n",
        "            conj_feat = extract_color_histogram(conj_masked)\n",
        "            conj_pred = conj_rf_model.predict(conj_feat)[0]\n",
        "            result['conjunctiva_prediction'] = int(conj_pred)\n",
        "        except Exception as e:\n",
        "            traceback.print_exc()\n",
        "            result['conjunctiva_prediction'] = None\n",
        "\n",
        "        # ---- Combine ----\n",
        "        predictions = [\n",
        "            result.get('nail_prediction'),\n",
        "            result.get('palm_prediction'),\n",
        "            result.get('conjunctiva_prediction')\n",
        "        ]\n",
        "\n",
        "        # fallback for combine_results to handle missing predictions\n",
        "        safe_predictions = [p if p in [0, 1] else 1 for p in predictions]\n",
        "        result['final_diagnosis'] = combine_results(safe_predictions)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ----- Start server -----\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "e2OubTZyd_rv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bd8dd4-c37c-425c-9e5b-4fc6341804e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://593e-34-125-90-167.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [639]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "INFO:     154.177.143.76:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [639]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QkFZZyECE-Df"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}